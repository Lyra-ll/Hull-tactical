# main.py
# =================================================================
# è‡ªåŠ¨åŒ–æŒ‡æŒ¥ä¸­å¿ƒ V2.9 (ç»ˆæç»Ÿä¸€ä¿®å¤ç‰ˆ)
# =================================================================
import argparse
import json
import time
import pandas as pd
import numpy as np
import lightgbm as lgb
import optuna
from sklearn.feature_selection import RFE
from sklearn.metrics import roc_auc_score
import torch
import copy
import importlib 
import sys

# å…¼å®¹Windowsæ§åˆ¶å°ç¼–ç ï¼Œå¼ºåˆ¶UTF-8ä»¥é¿å…UnicodeEncodeError
try:
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')
except Exception:
    pass

# Optunaç›¸å…³å¯¼å…¥
import optuna.integration
from optuna.integration import LightGBMPruningCallback

# -----------------------------------------------------------------
# å‡½æ•°å®šä¹‰åŒº
# -----------------------------------------------------------------

class MultiFoldPruningCallback:
    """
    ä¸€ä¸ªèƒ½åœ¨å¤šæŠ˜äº¤å‰éªŒè¯ä¸­å®ç°â€œNæŒ¯å‡ºå±€â€é€»è¾‘çš„æ™ºèƒ½å‰ªæå›è°ƒã€‚
    """
    def __init__(self, trial: optuna.trial.Trial, n_strikes: int = 3, metric: str = 'auc', step_base: int = 0):
        self.trial = trial
        self.n_strikes = n_strikes
        self.metric = metric
        self.current_strikes = 0
        self._step = 0
        self.step_base = step_base

    def __call__(self, env: lgb.callback.CallbackEnv) -> None:
        # æ¯æ¬¡è¢«è°ƒç”¨æ—¶ï¼Œéƒ½ä» LightGBM çš„ç¯å¢ƒä¸­è·å–å½“å‰çš„åˆ†æ•°
        current_score = env.evaluation_result_list[0][2]
        
        # ä½¿ç”¨å…¨å±€å”¯ä¸€çš„ stepï¼šstep_base + å½“å‰è¿­ä»£æ•°ï¼ˆè‹¥ä¸å¯ç”¨åˆ™ä½¿ç”¨å†…éƒ¨è®¡æ•°å™¨ï¼‰
        iteration = getattr(env, 'iteration', None)
        if iteration is None:
            step = self.step_base + self._step
            self._step += 1
        else:
            step = self.step_base + int(iteration)
        
        # å°†åˆ†æ•°æ±‡æŠ¥ç»™ Optuna
        self.trial.report(current_score, step)

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å‰ªæ
        if self.trial.should_prune():
            # Optuna è®¤ä¸ºåŸºäºå†å²è®°å½•ï¼Œè¿™ä¸ª trial å·²ç»æ²¡æœ‰å¸Œæœ›äº†
            self.current_strikes += 1 # è®°ä¸€æ¬¡â€œè­¦å‘Šâ€
            if self.current_strikes >= self.n_strikes:
                # å¦‚æœè­¦å‘Šæ¬¡æ•°è¾¾åˆ°äº†ä¸Šé™ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸ï¼ŒçœŸæ­£åœ°â€œæªæ¯™â€è¿™ä¸ªtrial
                message = f"Trial was pruned at step {step} after {self.current_strikes} strikes."
                raise optuna.exceptions.TrialPruned(message)

def run_rfe(X, y, config, utils):
    print(f"\n--- å¯åŠ¨ 'RFE' æ¨¡å¼: æ­£åœ¨åŸºäºä¸»ç›®æ ‡ '{config.PRIMARY_TARGET_COLUMN}' è¿›è¡Œç‰¹å¾æ’åº ---")
    
    # [æ ¸å¿ƒä¿®å¤] RFEçš„è¯„ä¼°å™¨ä¹Ÿå¿…é¡»ä»åˆ†ç±»å™¨å‡çº§ä¸ºå›å½’å™¨
    estimator = lgb.LGBMRegressor(random_state=42, verbosity=-1)

    tscv = utils.get_cv_splitter(config.N_SPLITS, config.EMBARGO_SIZE, config.PURGE_SIZE)
    all_rankings = []
    y_primary = y[config.PRIMARY_TARGET_COLUMN]

    for fold, (train_idx, _) in enumerate(tscv.split(X)):
        print(f"  > æ­£åœ¨ç¬¬ {fold + 1}/{config.N_SPLITS} æŠ˜ä¸Šè¿è¡ŒRFE...")
        purged_train_idx = train_idx[:-config.PURGE_SIZE] if config.PURGE_SIZE > 0 else train_idx
        
        X_train_rfe = X.iloc[purged_train_idx]
        y_train_rfe = y_primary.iloc[purged_train_idx]
        
        preprocessor_params = utils.get_preprocessor_params(X_train_rfe)
        X_train_rfe_filled, _ = utils.apply_preprocessor(X_train_rfe, preprocessor_params)
        
        selector = RFE(estimator=estimator, n_features_to_select=config.N_FEATURES_TO_SELECT_RFE, step=0.1)
        selector.fit(X_train_rfe_filled, y_train_rfe)
        
        all_rankings.append(pd.Series(selector.ranking_, index=X.columns))

    avg_ranking = pd.concat(all_rankings, axis=1).mean(axis=1).sort_values()
    avg_ranking.to_csv(config.RANKING_FILE, header=False)
    print(f"\nâœ… RFEæ’åå®Œæˆï¼æ’åå·²ä¿å­˜è‡³ '{config.RANKING_FILE}'")

# [æ ¸å¿ƒä¿®å¤] é‡æ„æŠ˜å†…é€»è¾‘ï¼Œä½¿ç”¨æ–°çš„ç»Ÿä¸€é¢„å¤„ç†å™¨
def _run_fold_logic(X_train, y_train, sw_train, X_val, y_val, sw_val, ae_params, lgbm_params, config, utils):
    device = torch.device("cpu")  # å¼ºåˆ¶ä½¿ç”¨CPUï¼Œé¿å…CUDAè®¾å¤‡ä¸ä¸€è‡´

    # 1. ä»è®­ç»ƒé›†å­¦ä¹ é¢„å¤„ç†å‚æ•°
    preprocessor_params = utils.get_preprocessor_params(X_train)

    # 2. åº”ç”¨å‚æ•°åˆ°è®­ç»ƒé›†å’ŒéªŒè¯é›†
    X_train_proc, X_train_scaled = utils.apply_preprocessor(X_train, preprocessor_params)
    X_val_proc, X_val_scaled = utils.apply_preprocessor(X_val, preprocessor_params)

    # --- [!!! å…³é”®ä¿®å¤ !!!] ---
    # è°ƒç”¨ train_fold_ae æ—¶ï¼Œy_train å’Œ y_val å¿…é¡»æ˜ç¡®åªé€‰æ‹©ç”¨äºç›‘ç£AEçš„è½¯ç›®æ ‡åˆ—ã€‚
    # y_train å’Œ y_val åœ¨è¿™é‡Œæ˜¯åŒ…å«äº†6ä¸ªç›®æ ‡åˆ—çš„DataFrameã€‚
    # æˆ‘ä»¬é€šè¿‡ .values å°†å…¶è½¬æ¢ä¸ºNumpyæ•°ç»„ï¼Œä»¥åŒ¹é…å‡½æ•°ç­¾åã€‚
    ae_models = utils.train_fold_ae(
        ae_params,
        X_train_scaled.values,
        y_train[config.TARGET_COLUMNS].values, # ä¹‹å‰æ˜¯ y_train.values (é”™è¯¯)
        sw_train.values,
        X_val_scaled.values,
        y_val[config.TARGET_COLUMNS].values,   # ä¹‹å‰æ˜¯ y_val.values (é”™è¯¯)
        sw_val.values,
        X_train.isnull().values,
        X_val.isnull().values,
        seeds=[42, 2024]
    )
    # --- [ä¿®å¤ç»“æŸ] ---
    
    if not ae_models: 
        return np.full((len(X_val), len(config.TARGET_COLUMNS)), 0.5)
        
    # 4. ç”ŸæˆAIç‰¹å¾
    with torch.no_grad():
        train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32).to(device)
        val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32).to(device)
        X_train_ai = np.mean([m.encoder(train_tensor).cpu().numpy() for m in ae_models], axis=0)
        X_val_ai = np.mean([m.encoder(val_tensor).cpu().numpy() for m in ae_models], axis=0)
        
    ai_cols = [f'{config.AI_PREFIX}{i}' for i in range(X_train_ai.shape[1])]
    X_train_ai_df = pd.DataFrame(X_train_ai, columns=ai_cols, index=X_train_proc.index)
    X_val_ai_df = pd.DataFrame(X_val_ai, columns=ai_cols, index=X_val_proc.index)

    X_train_final = pd.concat([X_train_scaled, X_train_ai_df], axis=1)
    X_val_final = pd.concat([X_val_scaled, X_val_ai_df], axis=1)

    # 5. è®­ç»ƒå¹¶é¢„æµ‹LGBM
    fold_preds = []
    # LGBMçš„è®­ç»ƒç›®æ ‡ä¾ç„¶æ˜¯è½¯æ ‡ç­¾ï¼Œè¿™éƒ¨åˆ†æ˜¯æ­£ç¡®çš„
    for target_col in config.TARGET_COLUMNS:
        model = lgb.LGBMRegressor(**lgbm_params).fit(X_train_final, y_train[target_col], sample_weight=sw_train)
        fold_preds.append(model.predict(X_val_final))
        
    return np.vstack(fold_preds).T


# [V3.1 ç»ˆææ€§èƒ½ä¼˜åŒ–ä¿®å¤ç‰ˆ]
def run_tuning(X, y, y_action, sample_weight, tune_target, config, utils):
    print(f"\n--- å¯åŠ¨ '{tune_target.upper()}' è°ƒä¼˜æ¨¡å¼ (V3.1 ç»ˆææ€§èƒ½ä¼˜åŒ–ä¿®å¤ç‰ˆ) ---")
    tscv_fortuning = utils.get_cv_splitter(config.N_SPLITS, config.EMBARGO_SIZE, config.PURGE_SIZE)
    folds_to_use = list(tscv_fortuning.split(X))
    print(f"    > [ç¨³å¥æ€§] Optunaå°†ä½¿ç”¨ {len(folds_to_use)} æŠ˜CVæ•°æ®è¿›è¡Œè¯„ä¼°...")
    
    y_all_targets = pd.concat([y, y_action], axis=1)
    # å†’çƒŸé…ç½®ä¸‹TARGETä¸ACTIONåŒåï¼Œæ‹¼æ¥ä¼šå‡ºç°é‡å¤åˆ—ï¼Œè¿™é‡Œå»é‡ä»¥é¿å…n_targetsé”™è¯¯ç¿»å€
    y_all_targets = y_all_targets.loc[:, ~y_all_targets.columns.duplicated()]

    def objective(trial):
        if tune_target == 'lgbm':
            try:
                with open(config.AE_PARAMS_FILE, 'r') as f: ae_params = json.load(f)
            except FileNotFoundError:
                ae_params = {'hidden_dim': 128, 'encoding_dim': 32, 'n_hidden_layers': 2, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'recon_weight': 0.5, 'bn':True}
            
            lgbm_params = { 
                'random_state': 42, 'n_jobs': -1, 'verbosity': -1, 
                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05, log=True), 
                'n_estimators': trial.suggest_int('n_estimators', 100, 2000), 
                'num_leaves': trial.suggest_int('num_leaves', 10, 80), 
                'reg_alpha': trial.suggest_float('reg_alpha', 1e-2, 50.0, log=True), 
                'reg_lambda': trial.suggest_float('reg_lambda', 1e-2, 50.0, log=True),
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),
                'subsample': trial.suggest_float('subsample', 0.7, 1.0),
            }
        elif tune_target == 'ae':
            with open(config.LGBM_PARAMS_FILE, 'r') as f: lgbm_params = json.load(f)
            lgbm_params.update({'random_state': 42, 'n_jobs': -1, 'verbosity': -1})
            ae_params = { 'hidden_dim': trial.suggest_int('hidden_dim', 64, 256, step=32), 'encoding_dim': trial.suggest_int('encoding_dim', 16, 64, step=8), 'n_hidden_layers': trial.suggest_int('n_hidden_layers', 1, 3), 'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5), 'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True), 'recon_weight': trial.suggest_float('recon_weight', 0.2, 0.8), 'bn': True }
        
        oof_predictions_trial = np.zeros((len(X), len(config.TARGET_COLUMNS)))
        oof_valid_mask = np.zeros(len(X), dtype=bool)

        for fold, (train_idx, val_idx) in enumerate(folds_to_use):
            # ä¸ºæ¯ä¸€æŠ˜æä¾›ä¸€ä¸ªä¸åŒçš„ step_baseï¼Œé¿å…ä¸åŒæŠ˜ä¹‹é—´çš„ step å†²çª
            # è¿™é‡ŒæŒ‰æ¯ä¸ªç›®æ ‡æœ€å¤šè¿­ä»£æ•°è¿‘ä¼¼ä¼°è®¡ï¼šä½¿ç”¨n_estimatorsä½œä¸ºæ¯æŠ˜çš„æ­¥é•¿åŸºæ•°
            step_base = fold * trial.params.get('n_estimators', 1000)
            pruning_callback_fold = MultiFoldPruningCallback(trial, n_strikes=3, metric='auc', step_base=step_base)
            purged_train_idx = train_idx[:-config.PURGE_SIZE] if config.PURGE_SIZE > 0 else train_idx
            
            X_train, sw_train = X.iloc[purged_train_idx], sample_weight.iloc[purged_train_idx]
            y_train_all = y_all_targets.iloc[purged_train_idx]
            X_val, y_val_all, sw_val = X.iloc[val_idx], y_all_targets.iloc[val_idx], sample_weight.iloc[val_idx]

            missing_ratios_fold = X_train.isnull().mean()
            features_to_keep_fold = missing_ratios_fold[missing_ratios_fold < config.MISSING_THRESHOLD].index.tolist()
            X_train_fold_filtered = X_train[features_to_keep_fold]
            X_val_fold_filtered = X_val[features_to_keep_fold]

            if tune_target == 'lgbm':
                # --- [!!! ç»ˆæé€»è¾‘ä¿®å¤ !!!] ---
                # 1. é¢„å¤„ç†
                preprocessor_params = utils.get_preprocessor_params(X_train_fold_filtered)
                _, X_train_scaled = utils.apply_preprocessor(X_train_fold_filtered, preprocessor_params)
                _, X_val_scaled = utils.apply_preprocessor(X_val_fold_filtered, preprocessor_params)
                
                # 2. ã€å…³é”®ã€‘åœ¨LGBMè°ƒä¼˜çš„æ¯ä¸€æŠ˜ä¸­ï¼Œä¹Ÿå¿…é¡»æ­£ç¡®åœ°ã€å®Œæ•´åœ°è®­ç»ƒAEæ¨¡å‹
                ae_models = utils.train_fold_ae(
                    ae_params, X_train_scaled.values, y_train_all[config.TARGET_COLUMNS].values, sw_train.values,
                    X_val_scaled.values, y_val_all[config.TARGET_COLUMNS].values, sw_val.values,
                    X_train_fold_filtered.isnull().values, X_val_fold_filtered.isnull().values
                )
                if not ae_models: continue

                # 3. ä»ã€è®­ç»ƒå¥½ã€‘çš„AEä¸­ç”ŸæˆAIç‰¹å¾
                device = torch.device("cpu")  # å¼ºåˆ¶ä½¿ç”¨CPUï¼Œé¿å…CUDAè®¾å¤‡ä¸ä¸€è‡´
                with torch.no_grad():
                    train_tensor = torch.tensor(X_train_scaled.values, dtype=torch.float32).to(device)
                    val_tensor = torch.tensor(X_val_scaled.values, dtype=torch.float32).to(device)
                    X_train_ai = np.mean([m.encoder(train_tensor).cpu().numpy() for m in ae_models], axis=0)
                    X_val_ai = np.mean([m.encoder(val_tensor).cpu().numpy() for m in ae_models], axis=0)
                
                ai_cols = [f'{config.AI_PREFIX}{i}' for i in range(X_train_ai.shape[1])]
                X_train_ai_df = pd.DataFrame(X_train_ai, columns=ai_cols, index=X_train_scaled.index)
                X_val_ai_df = pd.DataFrame(X_val_ai, columns=ai_cols, index=X_val_scaled.index)
                X_train_final = pd.concat([X_train_scaled, X_train_ai_df], axis=1)
                X_val_final = pd.concat([X_val_scaled, X_val_ai_df], axis=1)
                
                pruning_callback = LightGBMPruningCallback(trial, "auc")

                # 4. ä½¿ç”¨é«˜è´¨é‡çš„ç‰¹å¾ï¼Œè®­ç»ƒLGBMå¹¶åº”ç”¨â€œæ™ºèƒ½å‰ªæâ€
                fold_preds = []
                for i, target_col in enumerate(config.TARGET_COLUMNS):
                    action_col = config.ACTION_COLUMNS[i]
                    
                    # 2. æˆ‘ä»¬åªå¯¹æœ€é‡è¦çš„é‚£ä¸ªæ¨¡å‹ (i==0) åº”ç”¨æˆ‘ä»¬æ–°çš„å‰ªæç­–ç•¥
                    active_callbacks = [pruning_callback_fold] if i == 0 else []
                    
                    model = lgb.LGBMRegressor(**lgbm_params)
                    # å¯é€‰ï¼šè‹¥é…ç½®å…è®¸ä¸”ç¯å¢ƒæ”¯æŒGPUç‰ˆLightGBMï¼Œå¯æ·»åŠ å¦‚ä¸‹å‚æ•°ï¼š
                    # if getattr(config, 'LGBM_USE_GPU', False):
                    #     model.set_params(device_type='gpu')
                    model.fit(
                        X_train_final, y_train_all[target_col], sample_weight=sw_train,
                        eval_set=[(X_val_final, y_val_all[action_col])],
                        eval_sample_weight=[sw_val],
                        eval_metric="auc",
                        callbacks=active_callbacks
                    )
                    fold_preds.append(model.predict(X_val_final))
                
                oof_predictions_trial[val_idx] = np.vstack(fold_preds).T
                # --- [ä¿®å¤ç»“æŸ] ---
            else: # tune_target == 'ae', é€»è¾‘ä¿æŒä¸å˜ï¼Œè°ƒç”¨_run_fold_logic
                fold_predictions = _run_fold_logic(
                    X_train_fold_filtered, y_train_all, sw_train, 
                    X_val_fold_filtered, y_val_all, sw_val, 
                    ae_params, lgbm_params, config, utils
                )
                oof_predictions_trial[val_idx] = fold_predictions
            
            oof_valid_mask[val_idx] = True

        # è¯„ä¼°é€»è¾‘ä¿æŒä¸å˜
        y_true_for_scoring = y_action.iloc[oof_valid_mask].values
        y_pred = oof_predictions_trial[oof_valid_mask]
        weight_for_scoring = np.nan_to_num(sample_weight.iloc[oof_valid_mask].values, nan=0.0)
        valid_weight_mask = weight_for_scoring > 0

        if y_true_for_scoring.shape[0] == 0 or not valid_weight_mask.any(): return 0.5
        y_true_filtered = y_true_for_scoring[valid_weight_mask]
        y_pred_filtered = y_pred[valid_weight_mask]

        scores = []
        for i in range(y_true_filtered.shape[1]):
            y_col = y_true_filtered[:, i]
            if np.unique(y_col).size < 2:
                scores.append(0.5)
            else:
                scores.append(roc_auc_score(y_col, y_pred_filtered[:, i]))

        return float(np.mean(scores)) if scores else 0.5
    
    # ... (å‡½æ•°å‰©ä½™çš„study.optimizeéƒ¨åˆ†æ— éœ€ä¿®æ”¹) ...
    if tune_target == 'lgbm':
        study = optuna.create_study(direction='maximize')
        study.optimize(objective, n_trials=config.N_TRIALS_LGBM)
        params_file = config.LGBM_PARAMS_FILE
    elif tune_target == 'ae':
        try:
            with open(config.LGBM_PARAMS_FILE, 'r') as f: pass
        except FileNotFoundError:
            print("âŒ é”™è¯¯: å¿…é¡»å…ˆè¿è¡Œ 'tune_lgbm' æ¨¡å¼ã€‚"); return
        study = optuna.create_study(direction='maximize')
        study.optimize(objective, n_trials=config.N_TRIALS_AE)
        params_file = config.AE_PARAMS_FILE
        
    print(f"\n{'='*25} Optunaæœç´¢ç»“æŸ {'='*25}")
    print(f"âœ… æœ€ä½³ {tune_target.upper()} å‚æ•° (AUC: {study.best_value:.8f}):")
    print(json.dumps(study.best_params, indent=4))
    with open(params_file, 'w') as f: json.dump(study.best_params, f, indent=4)
    print(f"-> å·²ä¿å­˜è‡³ '{params_file}'")

def run_validation(X, y, sample_weight, date_ids, config, utils):
    print("\n--- å¯åŠ¨ 'VALIDATE' æ¨¡å¼ (V2.9.2 DLSæœ€ç»ˆä¿®å¤ç‰ˆ) ---")
    try:
        with open(config.LGBM_PARAMS_FILE, 'r') as f: lgbm_params = json.load(f)
        
        # --- [!!! å…³é”®ä¿®å¤ !!!] ---
        # ç§»é™¤äº†æ‰€æœ‰åˆ†ç±»ä»»åŠ¡ä¸“å±çš„å‚æ•°('objective': 'binary', 'metric': 'auc')
        # LGBMRegressorä¼šè‡ªåŠ¨ä½¿ç”¨é»˜è®¤çš„å›å½’ç›®æ ‡(å¦‚'l2')
        lgbm_params.update({'random_state': 42, 'n_jobs': -1, 'verbosity': -1})
        # --- [ä¿®å¤ç»“æŸ] ---

        with open(config.AE_PARAMS_FILE, 'r') as f: ae_params = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: ç¼ºå°‘å‚æ•°æ–‡ä»¶: {e}ã€‚è¯·å…ˆè¿è¡Œæ‰€æœ‰tuneæ¨¡å¼ã€‚"); return

    print("âœ… å‚æ•°åŠ è½½æˆåŠŸã€‚å¼€å§‹äº¤å‰éªŒè¯...")
    tscv = utils.get_cv_splitter(config.N_SPLITS, config.EMBARGO_SIZE, config.PURGE_SIZE)
    oof_predictions = np.zeros((len(X), len(config.TARGET_COLUMNS)))
    oof_valid_mask = np.zeros(len(X), dtype=bool)
    fold_val_indices = []

    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
        print(f"\n{'='*20} æ­£åœ¨å¤„ç†ç¬¬ {fold + 1}/{config.N_SPLITS} æŠ˜ {'='*20}")
        purged_train_idx = train_idx[:-config.PURGE_SIZE] if config.PURGE_SIZE > 0 else train_idx
        X_train, y_train, sw_train = X.iloc[purged_train_idx], y.iloc[purged_train_idx], sample_weight.iloc[purged_train_idx]
        X_val, y_val, sw_val = X.iloc[val_idx], y.iloc[val_idx], sample_weight.iloc[val_idx]

        print(f"  > [Fold {fold + 1}] æ­£åœ¨åŸºäºå½“å‰è®­ç»ƒé›†è¿›è¡ŒåŠ¨æ€ç¼ºå¤±å€¼ç­›é€‰ (é˜ˆå€¼: < {config.MISSING_THRESHOLD})...")
        missing_ratios_fold = X_train.isnull().mean()
        features_to_keep_fold = missing_ratios_fold[missing_ratios_fold < config.MISSING_THRESHOLD].index.tolist()
        
        print(f"    - ç­›é€‰å‰ç‰¹å¾æ•°: {X_train.shape[1]}")
        print(f"    - ç­›é€‰åç‰¹å¾æ•°: {len(features_to_keep_fold)}")
        if X_train.shape[1] != len(features_to_keep_fold):
             print(f"    - å·²å‰”é™¤ {X_train.shape[1] - len(features_to_keep_fold)} ä¸ªç‰¹å¾ã€‚")

        X_train_fold_filtered = X_train[features_to_keep_fold]
        X_val_fold_filtered = X_val[features_to_keep_fold]

        fold_predictions = _run_fold_logic(
            X_train_fold_filtered, y_train, sw_train, 
            X_val_fold_filtered, y_val, sw_val, 
            ae_params, lgbm_params, config, utils
        )

        oof_predictions[val_idx] = fold_predictions
        oof_valid_mask[val_idx] = True
        fold_val_indices.append(val_idx)

    print(f"\n\n{'='*25} æœ€ç»ˆäº¤å‰éªŒè¯ç»“æŸ {'='*25}")
    print(f"  > [å† å†›ç­–ç•¥] æœ€ç»ˆè¯„ä¼°å°†åªä½¿ç”¨æœ€å {config.N_LAST_FOLDS_TO_USE_INFERENCE} æŠ˜çš„é¢„æµ‹ç»“æœã€‚")

    inference_indices = np.concatenate(fold_val_indices[-config.N_LAST_FOLDS_TO_USE_INFERENCE:])

    y_true_final = y[config.ACTION_COLUMNS].iloc[inference_indices]
    preds_final_df = pd.DataFrame(oof_predictions[inference_indices], index=y_true_final.index, columns=[f'pred_{c}' for c in config.TARGET_COLUMNS])
    weights_final = np.nan_to_num(sample_weight.iloc[inference_indices].values, nan=0.0)
    valid_weight_mask = weights_final > 0
    if not valid_weight_mask.any():
        print("  > Warning: no positive-weight samples available for OOF scoring; using all rows.")
        y_true_eval = y_true_final
        preds_eval_df = preds_final_df
    else:
        y_true_eval = y_true_final.iloc[valid_weight_mask]
        preds_eval_df = preds_final_df.iloc[valid_weight_mask]

    scores = {}
    for i, action_col in enumerate(config.ACTION_COLUMNS):
        pred_col = f'pred_{config.TARGET_COLUMNS[i]}'
        y_true_col = y_true_eval[action_col]
        y_pred_col = preds_eval_df[pred_col]
        if y_true_col.nunique(dropna=True) < 2:
            scores[action_col] = 0.5
        else:
            scores[action_col] = roc_auc_score(y_true_col, y_pred_col)

    for col, score in scores.items(): print(f"ğŸ¯ OOF AUC for '{col}': {score:.8f}")
    print("-" * 60 + f"\nğŸ† æœ€ç»ˆOOFå¹³å‡AUC: {np.mean(list(scores.values())):.8f}\n" + "-" * 60)

    oof_df_to_save = pd.concat([date_ids.iloc[oof_valid_mask].reset_index(drop=True), y.iloc[oof_valid_mask].reset_index(drop=True), pd.DataFrame(oof_predictions[oof_valid_mask], columns=[f'pred_{c}' for c in config.TARGET_COLUMNS]).reset_index(drop=True)], axis=1)
    oof_df_to_save.to_csv(config.OOF_OUTPUT_FILE, index=False)
    print(f"âœ… å®Œæ•´çš„OOFé¢„æµ‹å·²ä¿å­˜è‡³ '{config.OOF_OUTPUT_FILE}'ã€‚")

# [æ ¸å¿ƒä¿®å¤] å½»åº•é‡æ„Holdoutæ¨¡å¼ï¼Œç¡®ä¿æ•°æ®å¤„ç†æµç¨‹100%ç»Ÿä¸€
# [V3 - è¯Šæ–­ä¼˜å…ˆç‰ˆ] é‡æ„Holdoutæ¨¡å¼ï¼Œå®ç°æœ€ç»ˆçš„å†…éƒ¨éªŒè¯ä¸å¤–éƒ¨æŒæœ‰å¯¹æ¯”
# [V2.9 DLSä¿®å¤ç‰ˆ]
def run_holdout_validation(X_train_full, y_train_full, sw_train_full, X_holdout, y_holdout, sw_holdout, config, utils):
    device = torch.device("cpu")  # å¼ºåˆ¶ä½¿ç”¨CPUï¼Œé¿å…CUDAè®¾å¤‡ä¸ä¸€è‡´
    print("\n" + "="*20 + " å¯åŠ¨ 'HOLDOUT' æœ€ç»ˆå®¡åˆ¤æ¨¡å¼ (V2.9 DLSä¿®å¤ç‰ˆ) " + "="*20)
    try:
        with open(config.LGBM_PARAMS_FILE, 'r') as f: lgbm_params = json.load(f)
        lgbm_params.update({'random_state': 42, 'n_jobs': -1, 'verbosity': -1})
        with open(config.AE_PARAMS_FILE, 'r') as f: ae_params = json.load(f)
        print("âœ… å‚æ•°åŠ è½½æˆåŠŸã€‚")
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: ç¼ºå°‘å‚æ•°æ–‡ä»¶: {e}ã€‚"); return

    final_val_split_idx = int(len(X_train_full) * 0.9)
    print(f"\n--- 1. æ­£åœ¨åˆ›å»ºæœ€ç»ˆè®­ç»ƒé›† (å‰90%) å’Œå†…éƒ¨éªŒè¯é›† (å10%) ---")
    
    X_final_train = X_train_full.iloc[:final_val_split_idx]
    y_final_train = y_train_full.iloc[:final_val_split_idx] # åŒ…å«æ‰€æœ‰ç›®æ ‡åˆ—
    sw_final_train = sw_train_full.iloc[:final_val_split_idx]
    
    X_final_val = X_train_full.iloc[final_val_split_idx:]
    y_final_val = y_train_full.iloc[final_val_split_idx:] # åŒ…å«æ‰€æœ‰ç›®æ ‡åˆ—
    sw_final_val = sw_train_full.iloc[final_val_split_idx:]
    print(f"  > æœ€ç»ˆè®­ç»ƒé›†: {len(X_final_train)} è¡Œ | å†…éƒ¨éªŒè¯é›†: {len(X_final_val)} è¡Œ")

    print("\n--- 2. æ­£åœ¨ä»æœ€ç»ˆè®­ç»ƒé›†å­¦ä¹ é¢„å¤„ç†å‚æ•° ---")
    preprocessor_params = utils.get_preprocessor_params(X_final_train)
    
    print("--- 3. æ­£åœ¨åº”ç”¨å‚æ•°è½¬æ¢æ‰€æœ‰æ•°æ®é›† ---")
    _, X_final_train_scaled = utils.apply_preprocessor(X_final_train, preprocessor_params)
    _, X_final_val_scaled = utils.apply_preprocessor(X_final_val, preprocessor_params)
    _, X_holdout_scaled = utils.apply_preprocessor(X_holdout, preprocessor_params)
    
    print("\n--- 4. æ­£åœ¨è®­ç»ƒæœ€ç»ˆAEæ¨¡å‹ (ä½¿ç”¨æ—©åœç­–ç•¥) ---")
    ae_models = utils.train_fold_ae(
        ae_params, 
        X_final_train_scaled.values, y_final_train[config.TARGET_COLUMNS].values, sw_final_train.values,
        X_final_val_scaled.values, y_final_val[config.TARGET_COLUMNS].values, sw_final_val.values,
        X_final_train.isnull().values,
        X_final_val.isnull().values
    )
    if not ae_models: print("âŒ AEæ¨¡å‹è®­ç»ƒå¤±è´¥ã€‚"); return
    print("âœ… æœ€ç»ˆAEæ¨¡å‹è®­ç»ƒå®Œæˆã€‚")

    print("\n--- 5. æ­£åœ¨ä¸ºæ‰€æœ‰æ•°æ®é›†ç”ŸæˆAIç‰¹å¾ ---")
    with torch.no_grad():
        train_tensor = torch.tensor(X_final_train_scaled.values, dtype=torch.float32).to(device)
        val_tensor = torch.tensor(X_final_val_scaled.values, dtype=torch.float32).to(device)
        holdout_tensor = torch.tensor(X_holdout_scaled.values, dtype=torch.float32).to(device)
        
        X_train_ai = np.mean([m.encoder(train_tensor).cpu().numpy() for m in ae_models], axis=0)
        X_val_ai = np.mean([m.encoder(val_tensor).cpu().numpy() for m in ae_models], axis=0)
        X_holdout_ai = np.mean([m.encoder(holdout_tensor).cpu().numpy() for m in ae_models], axis=0)

    ai_cols = [f'{config.AI_PREFIX}{i}' for i in range(X_train_ai.shape[1])]
    X_train_ai_df = pd.DataFrame(X_train_ai, columns=ai_cols, index=X_final_train.index)
    X_val_ai_df = pd.DataFrame(X_val_ai, columns=ai_cols, index=X_final_val.index)
    X_holdout_ai_df = pd.DataFrame(X_holdout_ai, columns=ai_cols, index=X_holdout.index)
    
    X_train_final = pd.concat([X_final_train_scaled, X_train_ai_df], axis=1)
    X_val_final = pd.concat([X_final_val_scaled, X_val_ai_df], axis=1)
    X_holdout_final = pd.concat([X_holdout_scaled, X_holdout_ai_df], axis=1)

    print("\n--- 6. æ­£åœ¨è®­ç»ƒæœ€ç»ˆLGBMå›å½’æ¨¡å‹å¹¶è¿›è¡Œä¸¤åœºè¯„ä¼° ---")
    val_scores, holdout_scores = {}, {}
    val_weights = np.nan_to_num(sw_final_val.values, nan=0.0)
    val_valid_mask = val_weights > 0
    holdout_weights = np.nan_to_num(sw_holdout.values, nan=0.0)
    holdout_valid_mask = holdout_weights > 0
    if not val_valid_mask.any(): print('  > Warning: no positive-weight samples in internal validation; using all rows.')
    if not holdout_valid_mask.any(): print('  > Warning: no positive-weight samples in holdout; using all rows.')
    for i, target_col in enumerate(config.TARGET_COLUMNS):
        action_col = config.ACTION_COLUMNS[i]
        print(f"  > æ­£åœ¨è®­ç»ƒ '{target_col}' å¹¶ç”¨ '{action_col}' è¯„ä¼°...")
        
        # [æ ¸å¿ƒä¿®å¤] ä½¿ç”¨ LGBMRegressor
        model = lgb.LGBMRegressor(**lgbm_params).fit(X_train_final, y_final_train[target_col], sample_weight=sw_final_train)
        
        # [æ ¸å¿ƒä¿®å¤] ä½¿ç”¨ .predict()
        val_preds = model.predict(X_val_final)
        holdout_preds = model.predict(X_holdout_final)
        
        # [æ ¸å¿ƒä¿®å¤] è¯„ä¼°æ—¶ä½¿ç”¨æ­£ç¡®çš„ action åˆ—
        val_truth = y_final_val[action_col].values[val_valid_mask] if val_valid_mask.any() else y_final_val[action_col].values
        val_pred = val_preds[val_valid_mask] if val_valid_mask.any() else val_preds
        holdout_truth = y_holdout[action_col].values[holdout_valid_mask] if holdout_valid_mask.any() else y_holdout[action_col].values
        holdout_pred = holdout_preds[holdout_valid_mask] if holdout_valid_mask.any() else holdout_preds
        val_scores[action_col] = 0.5 if np.unique(val_truth).size < 2 else roc_auc_score(val_truth, val_pred)
        holdout_scores[action_col] = 0.5 if np.unique(holdout_truth).size < 2 else roc_auc_score(holdout_truth, holdout_pred)

    print(f"\n\n{'='*25} æœ€ç»ˆå®¡åˆ¤æ—¥ç»“æœå¯¹æ¯” {'='*25}")
    print("\n--- å†…éƒ¨éªŒè¯é›† (è€ƒå‰æ¨¡æ‹Ÿ) æˆç»© ---")
    for col, score in val_scores.items(): print(f"  ğŸ¯ å†…éƒ¨éªŒè¯ AUC for '{col}': {score:.8f}")
    avg_val_score = np.mean(list(val_scores.values()))
    print(f"  ----------------------------------------\n  ğŸ† å†…éƒ¨éªŒè¯å¹³å‡AUC: {avg_val_score:.8f}\n")
    
    print("--- å¤–éƒ¨æŒæœ‰é›† (æ­£å¼é«˜è€ƒ) æˆç»© ---")
    for col, score in holdout_scores.items(): print(f"  ğŸ¯ å¤–éƒ¨æŒæœ‰ AUC for '{col}': {score:.8f}")
    avg_holdout_score = np.mean(list(holdout_scores.values()))
    print(f"  ----------------------------------------\n  ğŸ† å¤–éƒ¨æŒæœ‰å¹³å‡AUC: {avg_holdout_score:.8f}\n")

    score_diff = avg_val_score - avg_holdout_score
    print("=" * 65)
    print(f"è¯Šæ–­åˆ†æ: å†…éƒ¨éªŒè¯ä¸å¤–éƒ¨æŒæœ‰åˆ†æ•°å·®è·: {score_diff:.8f}")
    print("=" * 65)


# -----------------------------------------------------------------
# ä¸»ç¨‹åºå…¥å£ (V2.9.1 æœ€ç»ˆæ ¡å‡†ç‰ˆ)
# -----------------------------------------------------------------
if __name__ == '__main__':
     # --- [!!! å…³é”®ä¿®å¤ !!!] ---
    # å¯¼å…¥å¤šè¿›ç¨‹åº“
    import torch.multiprocessing as mp
    
    # åœ¨Windowsä¸Šä½¿ç”¨å¤šæ ¸DataLoaderæ—¶ï¼Œå¿…é¡»æ·»åŠ è¿™è¡Œä»£ç ã€‚
    # å®ƒå‘Šè¯‰PyTorchä»¥ä¸€ç§æ›´å®‰å…¨ã€å¹²å‡€çš„æ–¹å¼æ¥å¯åŠ¨æ–°çš„â€œå¸®å¨â€è¿›ç¨‹ï¼Œ
    # ä»è€Œé¿å…CUDAå’Œè¿›ç¨‹åˆå§‹åŒ–ä¹‹é—´çš„å†²çªï¼Œé˜²æ­¢æ­»é”ã€‚
    # è¿™å¿…é¡»æ˜¯ä¸»ç¨‹åºå…¥å£çš„ç¬¬ä¸€è¡Œå¯æ‰§è¡Œä»£ç ã€‚
    try:
        mp.set_start_method('spawn', force=True)
        print("\n--- [å¤šè¿›ç¨‹æ¨¡å¼] å·²æˆåŠŸè®¾ç½®ä¸º 'spawn' ---")
    except RuntimeError:
        pass
    # --- [ä¿®å¤ç»“æŸ] ---
    parser = argparse.ArgumentParser(description="è‡ªåŠ¨åŒ–æœºå™¨å­¦ä¹ ä½œæˆ˜å¹³å° V2.9.1 (DLSæœ€ç»ˆæ ¡å‡†ç‰ˆ)")
    parser.add_argument('--mode', type=str, required=True, choices=['rfe', 'tune_lgbm', 'tune_ae', 'validate', 'holdout'])
    parser.add_argument('--config', type=str, default='config', help="é…ç½®æ–‡ä»¶ (e.g., 'config', 'smoke')")
    args = parser.parse_args()

    try:
        config_module = importlib.import_module(args.config)
        print(f"--- é…ç½®æ–‡ä»¶ '{args.config}.py' åŠ è½½æˆåŠŸ ---")
    except ImportError:
        print(f"âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ°é…ç½®æ–‡ä»¶ '{args.config}.py'ã€‚"); exit()

    import utils
    start_time = time.time()
    
    print("\n--- å¯åŠ¨ç»Ÿä¸€æ•°æ®åŠ è½½ ---")
    dev_df = utils.load_data(config_module.RAW_DATA_FILE, config_module.ANALYSIS_START_DATE_ID)
    
    print("--- å¯åŠ¨ç»Ÿä¸€ç‰¹å¾ç­›é€‰ ---")
    
    all_available_features = [c for c in dev_df.columns if c.startswith(('M', 'E', 'I', 'P', 'V', 'S', 'D')) or '_diff' in c or '_rol_' in c]

    if args.mode == 'rfe':
        top_features = all_available_features
        print(f"  > [RFEæ¨¡å¼] å·²æ¿€æ´»ã€‚å°†ä½¿ç”¨å…¨éƒ¨ {len(top_features)} ä¸ªå¯ç”¨ç‰¹å¾è¿›è¡Œæ’åºã€‚")
    else:
        try:
            ranking = pd.read_csv(config_module.RANKING_FILE, index_col=0, header=None).squeeze("columns")
            top_features_from_file = ranking.nsmallest(config_module.N_TOP_FEATURES_TO_USE).index.tolist()
            top_features = [feat for feat in top_features_from_file if feat in all_available_features]
            print(f"  > å·²åŠ è½½æ’åï¼Œå°†ä½¿ç”¨ {len(top_features)} ä¸ªåœ¨å½“å‰æ•°æ®ä¸­å¯ç”¨çš„Topç‰¹å¾ã€‚")
        except FileNotFoundError:
            top_features = all_available_features
            print(f"  > è­¦å‘Š: æœªæ‰¾åˆ°ç‰¹å¾æ’åæ–‡ä»¶ '{config_module.RANKING_FILE}'ã€‚")
            print(f"  > å°†ä½¿ç”¨å…¨éƒ¨ {len(top_features)} ä¸ªå¯ç”¨ç‰¹å¾ã€‚")

    # --- [!!! å…³é”®ä¿®å¤ !!!] ---
    # åˆ†åˆ«å‡†å¤‡ X, y(è½¯ç›®æ ‡), y_action(ç¡¬ç›®æ ‡), å’Œæ ·æœ¬æƒé‡
    X_dev = dev_df[top_features]
    y_dev_dls = dev_df[config_module.TARGET_COLUMNS] # ç”¨äºè®­ç»ƒçš„è½¯ç›®æ ‡
    y_dev_action = dev_df[config_module.ACTION_COLUMNS] # ç”¨äºè¯„ä¼°çš„ç¡¬ç›®æ ‡
    y_dev_all = dev_df[config_module.TARGET_COLUMNS + config_module.ACTION_COLUMNS] # åŒ…å«æ‰€æœ‰ç›®æ ‡çš„ç‰ˆæœ¬

    date_ids_dev = dev_df[['date_id']]
    
    print("--- æ­£åœ¨åŠ è½½é¢„è®¡ç®—çš„å®‰å…¨æ ·æœ¬æƒé‡ ---")
    if 'sample_weight' in dev_df.columns:
        sample_weight_dev = dev_df['sample_weight']
        print("  > âœ… 'sample_weight' åˆ—åŠ è½½æˆåŠŸã€‚")
    else:
        print("  > âŒ é”™è¯¯: æœªåœ¨æ•°æ®æ–‡ä»¶ä¸­æ‰¾åˆ° 'sample_weight' åˆ—ï¼è¯·å…ˆé‡æ–°è¿è¡Œ create_features.pyã€‚")
        exit()

    # æ ¹æ®ä¸åŒçš„æ¨¡å¼ï¼Œè°ƒç”¨å¯¹åº”çš„å‡½æ•°ï¼Œå¹¶ä¼ é€’æ­£ç¡®çš„å‚æ•°
    if args.mode == 'holdout':
        print(f"  > [Holdoutæ¨¡å¼] æ­£åœ¨åŠ è½½æŒæœ‰é›†: '{config_module.HOLDOUT_DATA_FILE}'")
        holdout_df = utils.load_data(config_module.HOLDOUT_DATA_FILE, -1) # holdoutä¸ç­›é€‰date_id
        if 'sample_weight' in holdout_df.columns:
            sample_weight_holdout = holdout_df['sample_weight'].fillna(0.0)
        else:
            sample_weight_holdout = holdout_df[config_module.RESP_COLUMNS].abs().sum(axis=1).fillna(0.0)
        
        X_holdout = holdout_df[top_features]
        # holdoutçš„yä¹Ÿéœ€è¦åŒ…å«æ‰€æœ‰ç›®æ ‡åˆ—
        y_holdout_all = holdout_df[config_module.TARGET_COLUMNS + config_module.ACTION_COLUMNS]
        
        # è°ƒç”¨å·²å‡çº§çš„ run_holdout_validation å‡½æ•°
        run_holdout_validation(X_dev, y_dev_all, sample_weight_dev, X_holdout, y_holdout_all, sample_weight_holdout, config_module, utils)
    
    elif args.mode == 'rfe':
        # rfe åªéœ€è¦è½¯ç›®æ ‡æˆ–ç¡¬ç›®æ ‡ä¹‹ä¸€å³å¯ï¼Œè¿™é‡Œç”¨è½¯ç›®æ ‡ä¿æŒä¸€è‡´
        run_rfe(X_dev, y_dev_dls, config_module, utils)

    elif args.mode == 'tune_lgbm' or args.mode == 'tune_ae':
        # è°ƒç”¨å·²å‡çº§çš„ run_tuning å‡½æ•°ï¼Œåˆ†åˆ«ä¼ å…¥è½¯ç›®æ ‡å’Œç¡¬ç›®æ ‡
        run_tuning(X_dev, y_dev_dls, y_dev_action, sample_weight_dev, args.mode.split('_')[1], config_module, utils)

    elif args.mode == 'validate':
        # è°ƒç”¨å·²å‡çº§çš„ run_validation å‡½æ•°ï¼Œä¼ å…¥åŒ…å«æ‰€æœ‰ç›®æ ‡çš„y
        run_validation(X_dev, y_dev_all, sample_weight_dev, date_ids_dev, config_module, utils)
    # --- [ä¿®å¤ç»“æŸ] ---

    print(f"\nä»»åŠ¡ '{args.mode}' å®Œæˆï¼æ€»è€—æ—¶: {time.time() - start_time:.2f} ç§’ã€‚")
