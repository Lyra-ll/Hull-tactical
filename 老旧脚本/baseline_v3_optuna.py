import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt


# --- å…¨å±€é…ç½® ---
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

def find_robust_start_date(df: pd.DataFrame, completeness_threshold: float = 0.75) -> int:
    # ... (æ­¤å‡½æ•°æ— å˜åŒ–)
    print(f"--- ä»»åŠ¡ 1: åŠ¨æ€è®¡ç®—åˆ†æèµ·ç‚¹ ---")
    feature_cols = [col for col in df.columns if col.startswith(('D', 'E', 'I', 'M', 'P', 'S', 'V'))]
    df['feature_completeness'] = df[feature_cols].notna().sum(axis=1) / len(feature_cols)
    robust_start_date = df.loc[df['feature_completeness'] >= completeness_threshold, 'date_id'].iloc[0]
    print(f"è®¡ç®—å®Œæˆï¼ç¨³å¥çš„åˆ†æèµ·ç‚¹ date_id ä¸º: {robust_start_date}")
    return robust_start_date

def train_and_evaluate(X_train, y_train, X_val, y_val, lgb_params):
    """ä¸€ä¸ªç²¾ç®€çš„è®­ç»ƒå’Œè¯„ä¼°å‡½æ•°ã€‚"""
    model = lgb.LGBMRegressor(**lgb_params)
    model.fit(X_train, y_train,
              eval_set=[(X_val, y_val)],
              eval_metric='rmse',
              callbacks=[lgb.early_stopping(100, verbose=False)])

    preds = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, preds))
    return rmse

def find_robust_start_date(df: pd.DataFrame, completeness_threshold: float = 0.75) -> int:
    # ...
    print(f"--- ä»»åŠ¡ 1: åŠ¨æ€è®¡ç®—åˆ†æèµ·ç‚¹ ---")
    feature_cols = [col for col in df.columns if col.startswith(('D', 'E', 'I', 'M', 'P', 'S', 'V'))]
    df['feature_completeness'] = df[feature_cols].notna().sum(axis=1) / len(feature_cols)
    robust_start_date = df.loc[df['feature_completeness'] >= completeness_threshold, 'date_id'].iloc[0]
    print(f"è®¡ç®—å®Œæˆï¼ç¨³å¥çš„åˆ†æèµ·ç‚¹ date_id ä¸º: {robust_start_date}")
    return robust_start_date

def train_and_evaluate(X_train, y_train, X_val, y_val, lgb_params):
    # ...
    model = lgb.LGBMRegressor(**lgb_params)
    model.fit(X_train, y_train,
              eval_set=[(X_val, y_val)],
              eval_metric='rmse',
              callbacks=[lgb.early_stopping(100, verbose=False)])

    preds = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, preds))
    return rmse


if __name__ == '__main__':
    try:
        # --- æ­¥éª¤ 1: å‡†å¤‡æ•°æ® ---
        print("train_v3_featured_raw.csv")
        train_df = pd.read_csv('train_v3_featured_raw.csv')
        robust_start_date = find_robust_start_date(train_df)
        
        train_filtered = train_df[train_df['date_id'] > robust_start_date].copy()
        train_processed = train_filtered
        
        all_features = [col for col in train_processed.columns if col.startswith(('D', 'E', 'I', 'M', 'P', 'S', 'V'))]
        target = 'forward_returns'
        
        # ==================== ç»ˆæè¯Šæ–­ä»£ç  ====================
        print("\n--- [ç»ˆæè¯Šæ–­] æ­£åœ¨æ£€æŸ¥ç›®æ ‡(y)çš„ç¼ºå¤±æƒ…å†µ... ---")
        y_original = train_processed[target]
        y_nan_count = y_original.isnull().sum()
        y_total_count = len(y_original)
        print(f"  > åœ¨ date_id > {robust_start_date} çš„æ•°æ®èŒƒå›´å†…ï¼Œç›®æ ‡(y)å…±æœ‰ {y_total_count} è¡Œã€‚")
        print(f"  > å…¶ä¸­ï¼Œç¼ºå¤±çš„'æ ‡å‡†ç­”æ¡ˆ'(NaN)å…±æœ‰: {y_nan_count} è¡Œã€‚")
        print(f"  > ç¼ºå¤±ç‡: {y_nan_count / y_total_count:.4%}")
        print("--- è¯Šæ–­å®Œæ¯• ---")
        # =======================================================

        X = train_processed[all_features]
        y = train_processed[target].fillna(0) # æ‰§è¡Œå¿…è¦çš„æŠ€æœ¯æ€§å¡«å……
        X_train_full, X_val_full, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)
        
        # ... (åç»­ä»£ç å®Œå…¨æ— å˜åŒ–) ...
        print("\n--- ä»»åŠ¡ 2: åŠ è½½â€œé»„é‡‘å‚æ•°ç»„åˆâ€ ---")
        golden_params = {
            'objective': 'regression_l1', 'metric': 'rmse', 'n_estimators': 5000,
            'verbose': -1, 'n_jobs': -1, 'seed': 42, 'importance_type': 'gain',
            'learning_rate': 0.04485147098842579, 'num_leaves': 26,
            'feature_fraction': 0.70576707581891, 'bagging_fraction': 0.929368387238464,
            'bagging_freq': 7, 'min_child_samples': 12,
            'lambda_l1': 6.693101867960152e-08, 'lambda_l2': 0.1426934284068358
        }
        print("é»„é‡‘å‚æ•°å·²è£…è½½ï¼")

        print("\n--- ä»»åŠ¡ 3: ä½¿ç”¨é»„é‡‘å‚æ•°è¿›è¡Œä¸€æ¬¡æ€§ç‰¹å¾ä¾¦å¯Ÿ... ---")
        recon_model = lgb.LGBMRegressor(**golden_params).fit(X_train_full, y_train)
        feature_importance_df = pd.DataFrame({'feature': all_features, 'gain': recon_model.feature_importances_}).sort_values('gain', ascending=False)
        feature_pool = feature_importance_df.head(80)['feature'].tolist()
        print("Top 80 ç‰¹å¾æ± å·²å»ºç«‹ã€‚")

        print("\n--- ä»»åŠ¡ 4: åœ¨å·…å³°çŠ¶æ€ä¸‹ï¼Œå¯¹ä¸åŒè§„æ¨¡çš„éƒ¨é˜Ÿè¿›è¡Œæœ€ç»ˆè£å†³... ---")
        battle_plans = [30, 50, 80]
        results = {}

        for n_features in battle_plans:
            print(f"\n  > æ­£åœ¨è¯„ä¼° Top {n_features} éƒ¨é˜Ÿ...")
            current_features = feature_pool[:n_features]
            X_train_elite = X_train_full[current_features]
            X_val_elite = X_val_full[current_features]
            
            rmse_result = train_and_evaluate(X_train_elite, y_train, X_val_elite, y_val, golden_params)
            results[f'Top_{n_features}_Features'] = rmse_result
            print(f"    ...è¯„ä¼°å®Œæˆï¼ŒRMSE: {rmse_result}")

        print("\n" + "="*70)
        print("!!!               æœ€ç»ˆéªŒè¯æˆ˜æŠ¥æ±‡æ€»               !!!")
        print("="*70)
        best_plan = min(results, key=results.get)
        for plan, score in results.items():
            print(f">>> éƒ¨é˜Ÿè§„æ¨¡: {plan.replace('_', ' ')} | æœ€ç»ˆRMSE: {score}")
        print("\n--- [æœ€ç»ˆè£å†³] ---")
        print(f"ğŸ† åœ¨â€œé»„é‡‘å‚æ•°â€åŠ æŒä¸‹ï¼Œæœ€ä¼˜éƒ¨é˜Ÿè§„æ¨¡ä¸º: {best_plan.replace('_', ' ')}ï¼ğŸ†")
        print(f"    å…¶åˆ›é€ çš„æœ€æ–°RMSEè®°å½•ä¸º: {results[best_plan]}")
        print("="*70)

    except FileNotFoundError:
        print("\né”™è¯¯: train_v3_featured_raw.csv æ–‡ä»¶æœªæ‰¾åˆ°ã€‚")
    except Exception as e:
        print(f"\næ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")